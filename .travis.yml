sudo: required
language: python
jdk: openjdk8
services: docker
python: '3.6'
cache: pip
matrix:
  fast_finish: true

before_install:
  # PRs to master are only ok if coming from dev branch
  - '[ $TRAVIS_PULL_REQUEST = "false" ] || [ $TRAVIS_BRANCH != "master" ] || ([ $TRAVIS_PULL_REQUEST_SLUG = $TRAVIS_REPO_SLUG ] && ([ $TRAVIS_PULL_REQUEST_BRANCH = "dev" ] || [ $TRAVIS_PULL_REQUEST_BRANCH = "patch" ]))'
  # Pull the docker image first so the test doesn't wait for this
  - docker pull nfcore/eager:dev
  # Fake the tag locally so that the pipeline runs properly
  # Looks weird when this is :dev to :dev, but makes sense when testing code for a release (:dev to :1.0.1)
  - docker tag nfcore/eager:dev nfcore/eager:dev

install:
  # Install Nextflow
  - mkdir /tmp/nextflow && cd /tmp/nextflow
  - wget -qO- get.nextflow.io | bash
  - sudo ln -s /tmp/nextflow/nextflow /usr/local/bin/nextflow
  # Install nf-core/tools
  - pip install --upgrade pip
  - pip install nf-core
  # Install Conda 
  - wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh
  - bash Miniconda3-latest-Linux-x86_64.sh -b -f -p $HOME/miniconda
  - export PATH="$HOME/miniconda/bin:$PATH"
  # Reset
  - mkdir ${TRAVIS_BUILD_DIR}/tests && cd ${TRAVIS_BUILD_DIR}/tests
  # Install markdownlint-cli
  - sudo apt-get install npm && npm install -g markdownlint-cli

env:
  - NXF_VER='19.10.0' NXF_ANSI_LOG=0 RUN_NAME="eager-${TRAVIS_PULL_REQUEST_BRANCH}-${TRAVIS_JOB_NUMBER}" # Specify a minimum NF version that should be tested and work

script:
  # Lint the pipeline code
  - nf-core lint ${TRAVIS_BUILD_DIR}
  # REFERENCE: Run the basic pipeline with the test profile
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-basic" -profile test,docker --pairedEnd --saveReference
  # REFERENCE: Run the basic pipeline with single end data (pretending its single end actually) and all prepared index files
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-singleEnd" -profile test,docker --singleEnd
  # REFERENCE: Run the basic pipeline with FastA reference with `fna` extension
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-fna_ref" -profile test_fna,docker --pairedEnd --saveReference
  # REFERENCE: Test using pre-computed indices from a separate run beforehand
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-preindex_ref" -profile test_fna,docker --pairedEnd --bwa_index 'results/reference_genome/bwa_index/BWAIndex/Mammoth_MT_Krause.fna' --fasta_index 'results/reference_genome/fasta_index/Mammoth_MT_Krause.fna.fai' --seq_dict 'results/reference_genome/seq_dict/Mammoth_MT_Krause.dict'
  # REFERENCE: Test with zipped reference input
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-gz_ref" -profile test,docker --pairedEnd --fasta 'https://github.com/jfy133/test-datasets/raw/eager/reference/Mammoth/Mammoth_MT_Krause.fasta.gz'
  # FASTP: Run the same pipeline testing optional steps of fastp, complexity 
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-fastp" -profile test,docker --pairedEnd --complexity_filter
  # ADAPTERREMOVAL: Run the basic pipeline with paired end data without collapsing
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-skip_collapse" -profile test,docker --pairedEnd --skip_collapse
  # ADAPTERREMOVAL: Run the basic pipeline with paired end data without trimming, but still merge
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-pretrim" -profile test_pretrim,docker --pairedEnd --skip_trim
  # ADAPTERREMOVAL: Run the basic pipeline with paired end data without adapterRemoval
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-skip_adapterremoval" -profile test,docker --pairedEnd --skip_adapterremoval
  # ADAPTERREMOVAL: Run the basic pipeline with preserve5p end option
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-preserve5p" -profile test,docker --pairedEnd --preserve5p
  # ADAPTERREMOVAL: Run the basic pipeline with merged only option
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-mergedonly" -profile test,docker --pairedEnd --mergedonly
  # ADAPTERREMOVAL: Run the basic pipeline with preserve5p end and merged reads only options
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-preserve5p_mergedonly" -profile test,docker --pairedEnd --preserve5p --mergedonly
  # MAPPER_CIRCULARMAPPER: Test running with CircularMapper
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-circularmapper" -profile test,docker --pairedEnd --mapper 'circularmapper' --circulartarget 'NC_007596.2'
  # MAPPER_BWAMEM: Test running with BWA Mem
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-bwa_mem" -profile test,docker --pairedEnd --mapper 'bwamem'
  # STRIP_FASTQ: Run the basic pipeline with output unmapped reads as fastq
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-stripfastq" -profile test,docker --pairedEnd --strip_input_fastq
  # BAM_FILTERING: Run basic mapping pipeline with mapping quality filtering, and unmapped export
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-unmapped_export" -profile test,docker --pairedEnd --run_bam_filtering --bam_mapping_quality_threshold 37 --bam_discard_umapped --bam_unmapped_type 'fastq'
  # GENOTYPING_HC: Test running GATK HaplotypeCaller
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-haplotypercaller" -profile test_fna,docker --pairedEnd  --dedupper 'dedup' --run_genotyping --genotyping_tool 'hc' --gatk_out_mode 'EMIT_ALL_SITES' --gatk_hc_emitrefconf 'BP_RESOLUTION'
  # GENOTYPING_FB: Test running FreeBayes
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-freebayes" -profile test,docker --pairedEnd  --dedupper 'dedup' --run_genotyping --genotyping_tool 'freebayes'
  # SKIPPING: Test checking all skip steps work i.e. input bam, skipping straight to genotyping
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-skipping_logic" -profile test_bam,docker --bam --singleEnd --skip_fastqc --skip_adapterremoval --skip_mapping --skip_deduplication --skip_qualimap --skip_preseq --skip_damage_calculation --run_genotyping --genotyping_tool 'freebayes'
  # BAM_INPUT: Run the basic pipeline with the bam input profile, skip AdapterRemoval as no convertBam
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-baminput_noConvertBam" -profile test_bam,docker --bam --skip_adapterremoval --run_convertbam
  # BAM_INPUT: Run the basic pipeline with the bam input profile, convert to FASTQ for adapterremoval test and downstream
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-baminput_convertbam_basic" -profile test_bam,docker --bam --run_convertbam
  # METAGENOMIC Download database and Run the basic pipeline but with unmapped reads going into MALT
  - mkdir -p ${TRAVIS_BUILD_DIR}/databases/malt && for i in index0.idx ref.db ref.idx ref.inf table0.db table0.idx taxonomy.idx taxonomy.map taxonomy.tre; do wget https://github.com/nf-core/test-datasets/raw/eager/databases/malt/"$i" -P "${TRAVIS_BUILD_DIR}/databases/malt/"; done
  - nextflow run ${TRAVIS_BUILD_DIR} "$TOWER" -name "$RUN_NAME-malt" -profile test,docker --pairedEnd --run_bam_filtering --bam_discard_unmapped --bam_unmapped_type 'fastq' --run_metagenomic_screening --database "${TRAVIS_BUILD_DIR}/databases/malt/"
  # MALTEXTRACT Download NCBI db, ncbi map/tree, additional files and run test
  - mkdir -p ${TRAVIS_BUILD_DIR}/databases/maltextract && for i in ncbi.tre ncbi.map; do wget https://github.com/rhuebler/HOPS/raw/external/Resources/"$i" -P ${TRAVIS_BUILD_DIR}/databases/maltextract/; done
  - nextflow run ${TRAVIS_BUILD_DIR} "$TOWER" -name "$RUN_NAME-maltextract" -profile test,docker --pairedEnd --run_bam_filtering --bam_discard_unmapped --bam_unmapped_type 'fastq' --run_metagenomic_screening --metagenomic_tool 'malt' --database "${TRAVIS_BUILD_DIR}/databases/malt/" --run_maltextract --maltextract_ncbifiles "${TRAVIS_BUILD_DIR}/databases/maltextract/" --maltextract_taxon_list 'https://raw.githubusercontent.com/nf-core/test-datasets/eager/testdata/Mammoth/maltextract/MaltExtract_list.txt' 
  # SEXDETERMINAION: Run the basic pipeline with the bam input profile, but don't convert BAM, skip everything but sex determination
  - nextflow run ${TRAVIS_BUILD_DIR} "$TOWER" -name "$RUN_NAME-sexdeterrmine" -profile test_humanbam,docker --bam --skip_fastqc --skip_adapterremoval --skip_mapping --skip_deduplication --skip_qualimap --singleEnd --skip_preseq --skip_damage_calculation --run_sexdeterrmine
  # NUCLEAR CONTAMINATION ESTIMATION Premapped BAM run skipping most steps but run nuclear contamination with ANGSD
  - nextflow run ${TRAVIS_BUILD_DIR} "$TOWER" -name "$RUN_NAME-nuclearcontamination" -profile test_humanbam,docker --bam --skip_fastqc --skip_adapterremoval --skip_mapping --skip_deduplication --skip_qualimap --singleEnd --skip_preseq --skip_damage_calculation --run_nuclear_contamination
  # MTNUCRATIO Run basic pipeline with bam input profile, but don't convert BAM, skip everything but nmtnucratio
  - nextflow run ${TRAVIS_BUILD_DIR} "$TOWER" -name "$RUN_NAME-mtnucratio" -profile test_humanbam,docker --bam --skip_fastqc --skip_adapterremoval --skip_mapping --skip_deduplication --skip_qualimap --singleEnd --skip_preseq --skip_damage_calculation --run_mtnucratio
  # Download GATK 3.5 JAR
  - mkdir -p ${TRAVIS_BUILD_DIR}/jars && wget https://storage.googleapis.com/gatk-software/package-archive/gatk/GenomeAnalysisTK-3.5-0-g36282e4.tar.bz2 -P ${TRAVIS_BUILD_DIR}/jars && tar xjf ${TRAVIS_BUILD_DIR}/jars/GenomeAnalysisTK-3.5-0-g36282e4.tar.bz2
  # TRIM_BAM/PMD/GENOTYPING_UG/MULTIVCFANALYZER: Test running PMDTools, TrimBam, GATK UnifiedGenotyper and MultiVCFAnalyzer
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-pmd_trimbam_unifiedgenotyper_multivcfanalyzer" -profile test,docker --pairedEnd  --dedupper 'dedup' --run_trim_bam --run_pmdtools --run_genotyping --genotyping_source 'trimmed' --genotyping_tool 'ug' --gatk_ug_jar '${TRAVIS_BUILD_DIR}/jars/GenomeAnalysisTK.jar' --gatk_out_mode 'EMIT_ALL_SITES' --gatk_ug_genotype_model 'SNP' --run_multivcfanalyzer
  # GENOTYPING_UG/PMD/MULTIVCFANALYZER: Test running GATK UnifiedGenotyper and MultiVCFAnalyzer, additional VCFS
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-multivcfanalyzer_additionalvcfs" -profile test,docker --pairedEnd  --dedupper 'dedup' --run_genotyping --genotyping_tool 'ug' --gatk_ug_jar '${TRAVIS_BUILD_DIR}/jars/GenomeAnalysisTK.jar' --gatk_out_mode 'EMIT_ALL_SITES' --gatk_ug_genotype_model 'SNP' --run_multivcfanalyzer --additional_vcf_files 'https://raw.githubusercontent.com/jfy133/test-datasets/eager/testdata/Mammoth/vcf/JK2772_CATCAGTGAGTAGA_L008_R1_001.fastq.gz.tengrand.fq.combined.fq.mapped_rmdup.bam.unifiedgenotyper.vcf.gz' --write_allele_frequencies
  # VCF2GENOME: Test running GATK UnifiedGenotyper and run VCF2GENOME
  - nextflow run ${TRAVIS_BUILD_DIR} -name "$RUN_NAME-vcf2genome" -profile test,docker --pairedEnd  --dedupper 'dedup' --run_genotyping --genotyping_tool 'ug' --gatk_ug_jar '${TRAVIS_BUILD_DIR}/jars/GenomeAnalysisTK.jar' --genotyping_source 'raw' --gatk_out_mode 'EMIT_ALL_SITES' --gatk_ug_genotype_model 'SNP' --run_vcf2genome
